{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07dfd0b1-b4fe-4e5d-9888-7722472c199e",
   "metadata": {},
   "source": [
    "# \"Shazam\"\n",
    "\n",
    "Merci de remplir les informations ci-dessous, pour attribuer les notes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aca533-e6ed-47d8-a6bd-5ae264ef5bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N° de binôme (ex. binome_e99)\n",
    "# Nom des étudiants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cd29b7",
   "metadata": {},
   "source": [
    "## Consignes importantes\n",
    "\n",
    "Vous aurez des manipulations à faire dans BigQuery, des requêtes à mettre au point, et des réponses à trouver. Je note les requêtes et les réponses. Pour les requêtes, vous avez 2 possibilités :\n",
    "- soit les mettre au point directement dans le notebook\n",
    "- soit les mettre au point dans l'interface de BigQuery, auquel cas **vous devrez les recopier dans le notebook**. BigQuery tout seul ne sauve pas les requêtes et je ne regarde pas ce qu'il y a dans BigQuery. On doit pouvoir réexécuter le notebook d'un coup sans erreur.\n",
    "\n",
    "Il y a un notebook \"Prise en main\" qui n'est pas à rendre, mais vous aidera de temps en temps.\n",
    "\n",
    "Déroulé conseillé :\n",
    "- suivre la partie I du notebook \"Prise en main\"\n",
    "- faire la partie 1 de ce notebook\n",
    "- suivre la partie II de Prise en main\"\n",
    "- puis faire les parties 2 et 3 de ce notebook, en vous référant à la partie III de \"Prise en main\" lorsque nécessaire\n",
    "\n",
    "Dépendance entre les parties de ce notebook :\n",
    "- la partie 1 est nécessaire pour la suite\n",
    "- les parties 1 et 2 jusqu'à la question \"Enrichissement de la base de données\" sont nécessaires pour la partie 3\n",
    "- sauf la toute dernière question de la partie 3, qui est indépendante\n",
    "\n",
    "Si vous êtes bloqués : le dataset `shared` contient les tables que vous devez créer avec les requêtes, avec le préfixe `corrige__` (deux \"tirets du 8\"). Vous pouvez donc sauter une question en changeant le nom de la table (ex. `SELECT * FROM binome_xxx.raw_vectors` -> `SELECT * FROM shared.corrige__raw_vectors`). Le corrigé de l'UDF n'est pas donné en revanche.\n",
    "\n",
    "#### Merci de ne faire qu'un notebook \"TP3\" par binôme.\n",
    "\n",
    "#### A la fin du TP, avant de partir, sauvez ce notebook sur l'ordinateur, et envoyez-moi le fichier `TP3.ipynb` à l'adresse tvial@octo.com."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e36744-6f75-4f55-8271-55a8c5a1a331",
   "metadata": {},
   "source": [
    "## Contexte et données\n",
    "\n",
    "Vous développez un service de reconnaissance musicale (type Shazam), basé sur l’utilisation d’**embeddings** (vecteurs) censés représenter les “empreintes digitales” des morceaux. La recherche de morceaux proches d'un autre revient ainsi à calculer les distances entre des embeddings.\n",
    "\n",
    "Les données sont constituées de morceaux composés par des artistes ; chaque morceau a préalablement été transformé en un certain nombre de vecteurs, dont le nombre peut varier. En effet un vecteur encode environ 10 s de musique, un morceau de 200 secondes aura ainsi une vingtaine de vecteurs, et un morceau de 400 secondes une quarantaine.\n",
    "\n",
    "![](https://raw.githubusercontent.com/tvial/BUT-R6.01-TP3/refs/heads/main/images/vectors.png)\n",
    "\n",
    "### Informations sur les morceaux\n",
    "\n",
    "Le premier jeu de données est un fichier `metadata.csv`, qui énumère les un peu plus de 1400 morceaux. Il contient une ligne par morceau avec les champs suivants séparés par des `“;”` :\n",
    "- `song_id` : identifiant numérique du morceau\n",
    "- `artist` : nom de l’artiste\n",
    "- `title` : titre du morceau\n",
    "- `duration` : durée du morceau, en secondes (NB : cette information est fictive)\n",
    "\n",
    "### Vecteurs d'embedding\n",
    "\n",
    "Le deuxième jeu de données est un ensemble de fichiers “JSONL”, c’est-à-dire des groupes de documents JSON stockés dans un même fichier avec un document par ligne. Ces fichiers correspondent aux vecteurs issus des morceaux. Il y a au total 1367 documents, regroupés en 18 fichiers `vectors_001.jsonl` à `vectors_018.jsonl`.\n",
    "\n",
    "Il y a moins de documents que de morceaux (1367 contre 1418), car le calcul des embeddings a échoué pour quelques uns d'entre eux. Ce n'est pas gênant pour le TP.\n",
    "\n",
    "Chaque document JSON (une ligne de fichier JSONL donc) est structuré ainsi :\n",
    "- Un champ `“id”` qui contient l’ID du morceau (le même que dans le fichier `metadata.csv`)\n",
    "- Un champ `“vectors”` qui est un tableau d’objets :\n",
    "  - Chacun de ces objets a un seul champ `“vector”`, qui est un tableau de 16 nombres flottants\n",
    "  - Tous les vecteurs sont donc de la même taille (16), mais il y a un nombre variable de tels vecteurs pour un morceau donné\n",
    "\n",
    "En pratique, voici à quoi ressemble un fichier JSONL :\n",
    "```\n",
    "{“id”: 12, “vectors”: [{“vector”: [0.1, 0.2, ...]}, {“vector”: [0.4, 0.6, ...]}, ...]}\n",
    "{“id”: 13, “vectors”: [{“vector”: [0.6, 0.5, ...]}, {“vector”: [0.7, 0.9, ...]}, ...]}\n",
    "...\n",
    "```\n",
    "\n",
    "Les vecteurs ont été produits ainsi :\n",
    "- lecture de fichiers MP3\n",
    "- tranformation en embeddings avec le modèle [YAMNet](https://www.kaggle.com/models/google/yamnet)\n",
    "- réduction du volume :\n",
    "  - agrégation des fenêtres (10 vecteurs pour 1 seconde de musique => 1 vecteur pour 10 secondes, moyenne des 10 vecteurs)\n",
    "  - ACP pour diminuer la taille des vecteurs de 1024 à 16\n",
    "\n",
    "### Vecteurs de requêtes\n",
    "\n",
    "Enfin, il y a 3 morceaux inconnus qui seront confrontés à la base de données des vecteurs : ce seront les \"requêtes\" de Shazam. Elles sont dans un seul fichier JSONL, avec la même structure que les précédents (le champ `\"id\"` représente l'ID de requête et non plus de morceau).\n",
    "\n",
    "Toutes les données d’entrée sont dans le système de stockage objet de GCP, Google Cloud Storage, et nous allons les importer dans Big Query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6975fe6-e4fe-440a-8d35-76584c25b0d9",
   "metadata": {},
   "source": [
    "# Partie 1 : Manipulation dans BigQuery\n",
    "\n",
    "Dans cette partie, on ne fait que des manipulations dans l'interface de BigQuery. Le notebook sert juste de guide et je n'attends pas de requête.\n",
    "\n",
    "Prenez soin de respecter les étapes, car les données chargées serviront de base aux requêtes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612febe9-9670-41f6-9d00-36eae31b6698",
   "metadata": {},
   "source": [
    "## Import des informations sur les morceaux\n",
    "\n",
    "A l’aide de l’interface graphique, créer une table `metadata` dans votre dataset, dont les données se trouvent dans Google Cloud Storage.\n",
    "\n",
    "- Après avoir choisi le type de source, un champ apparaît avec un bouton “PARCOURIR”. En cliquant dessus, il faut sélectionner le “bucket” (espace de stockage) `but-tp-shazam-datalake`, et à l’intérieur, le fichier `metadata.csv`.\n",
    "- Le format doit être CSV\n",
    "- Vous pouvez cocher “Détection automatique” dans la section “Schéma” pour que BigQuery trouve tout seul les champs et leurs types\n",
    "- Attention, le séparateur de champs est un point-virgule dans le fichier, mais BigQuery suppose une virgule par défaut. Trouvez où changer ce paramètre\n",
    "- Ne changez pas les autres paramètres par défaut\n",
    "- Cliquez enfin sur “CREER LA TABLE” pour lancer le “job” de chargement\n",
    "\n",
    "Si tout s’est bien passé, vous ne devez pas avoir d’erreurs. Sinon, vérifiez bien les informations.\n",
    "\n",
    "En cliquant sur le nom de la table dans l’explorateur, vous pouvez voir la structure que Big Query a déduite, et en cliquant sur “PREVIEW”, avoir un extrait des données. Vérifiez bien que le contenu semble correct, sinon il faut supprimer la table (“Supprimer” depuis les 3 petits points de l’explorateur) et recommencer le chargement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4419fb6c-48d6-4768-be12-a67b12dd26bb",
   "metadata": {},
   "source": [
    "## Import des vecteurs d'embedding\n",
    "\n",
    "Créer de même une nouvelle table, `raw_vectors`, qui va cette fois contenir les vecteurs bruts tirés des documents JSON.\n",
    "\n",
    "- Ces données sont au format JSONL\n",
    "- BigQuery est capable de détecter le schéma comme pour metadata\n",
    "- Elles se trouvent dans le même bucket que `metadata.csv`, mais dans le répertoire `tracks`. Vous pouvez sélectionner un des fichiers du bucket, et remplacer ensuite son nom par un nom générique (ex. `vectors_001.jsonl` → `*.jsonl`) pour que BigQuery importe tout d’un coup\n",
    "\n",
    "Comme précédemment, vérifiez le résultat via l’explorateur. La structure doit ressembler à ceci :\n",
    "\n",
    "![](https://raw.githubusercontent.com/tvial/BUT-R6.01-TP3/refs/heads/main/images/struct_raw_vectors.png)\n",
    "\n",
    "Et la prévisualisation n’est pas très lisible, à cause des tableaux imbriqués dans des objets :\n",
    "\n",
    "![](https://raw.githubusercontent.com/tvial/BUT-R6.01-TP3/refs/heads/main/images/preview_raw_vectors.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde74db3-7901-4901-9838-76bf620ab7d1",
   "metadata": {},
   "source": [
    "## Import des requêtes\n",
    "\n",
    "Procéder de même pour les requêtes, dans le répertoire `queries`, pour créer une table `raw_queries`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55ddc1e-033e-4303-b622-a79393638e66",
   "metadata": {},
   "source": [
    "# Partie 2 : Requêtes dans le notebook\n",
    "\n",
    "Dans cette partie, il faut écrire les requêtes dans le notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999c5b2b",
   "metadata": {},
   "source": [
    "## Configuration de l'extension BigQuery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c993ca2f-45e3-4300-ac41-a8b2ba08b018",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext bigquery_magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5c99bf-e3a8-4a0f-8851-d4c86451da13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bigquery_magics\n",
    "bigquery_magics.context.project = 'but-tp'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161c23d3-e6fd-4d5e-b492-3dfbc52656b7",
   "metadata": {},
   "source": [
    "## Transposition des vecteurs\n",
    "\n",
    "Actuellement, les données de vecteurs dans la table ont un modèle calqué sur celui des fichiers, qui n’est donc pas très pratique. On cherche à les “dénormaliser”, c’est-à-dire à transformer chaque ligne (qui correspond à un morceau) en autant de lignes qu’il y a de vecteurs pour son morceau, en répétant l’ID du morceau.\n",
    "\n",
    "Schématiquement, cela revient à faire une opération de ce style pour chaque morceau (ici celui d’ID 42) :\n",
    "\n",
    "![](https://raw.githubusercontent.com/tvial/BUT-R6.01-TP3/refs/heads/main/images/transposition.png)\n",
    "\n",
    "Les ID sont répétés autant de fois qu’il y a de fenêtres et donc de vecteurs. Le nouveau champ `window_id` est le numéro de la fenêtre dans le morceau, i.e. la position du vecteur dans le tableau (le premier ayant la position 0).\n",
    "\n",
    "Mettre au point une requête `SELECT` qui fait cette transposition, puis créer une table `flat_vectors` avec le résultat. La table doit avoir la structure suivante :\n",
    "- `id` : l’ID du morceau\n",
    "- `window_id` : numéro de la fenêtre\n",
    "- `vector` : un vecteur unique = un tableau à 16 flottants\n",
    "\n",
    "Vous pouvez vous aider du notebook de \"Prise en main\", dans la partie III. Il faut en plus accéder au sous-tableau `vector` qui se situe à l’intérieur des éléments du tableau principal (analogue à `myarray` dans l’exemple). L’équivalent de `element` est alors un objet JSON, dont on peut extraire l’attribut vector grâce à la syntaxe suivante : `element.vector` (à utiliser dans la liste des colonnes après le `SELECT`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a459f6-05e2-4d45-92e9-d6a0cded7f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE ... AS ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60ea27d-56c1-47c7-9ce9-e3df05da0f5c",
   "metadata": {},
   "source": [
    "Vous devez obtenir 70 124 lignes, et l’aperçu dans BigQuery doit ressembler à ceci (l’ordre des morceaux et fenêtres est arbitraire) :\n",
    "\n",
    "![](https://raw.githubusercontent.com/tvial/BUT-R6.01-TP3/refs/heads/main/images/preview_flat_vectors.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946b5e4b-b798-4884-8515-c4e1b6f550ca",
   "metadata": {},
   "source": [
    "## Transposition des vecteurs de `raw_queries`\n",
    "\n",
    "Appliquer la même méthode pour créer une table `flat_queries`, à partir de `raw_queries`. La structure doit être la même."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c41d5e4-a611-4117-bad1-99b13cc24474",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1291270c-87e2-485d-ba1d-ccd77206746a",
   "metadata": {},
   "source": [
    "La table doit contenir 256 éléments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051097ce-6d29-4bdf-b148-053df04bdd09",
   "metadata": {},
   "source": [
    "## Enrichissement de la base de données\n",
    "\n",
    "Maintenant que nous avons des vecteurs à plat, nous allons enrichir la table avec les métadonnées des morceaux.\n",
    "\n",
    "Créer une table `vectors_with_metadata`, avec comme structure :\n",
    "- `song_id` (provient des deux tables)\n",
    "- `window_id` (provient de `flat_vectors`)\n",
    "- `artist` (provient de `metadata`)\n",
    "- `title` (provient de `metadata`)\n",
    "- `duration` (provient de `metadata`)\n",
    "- `vector` (provient de `flat_vectors`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c54242a-9064-45dd-acdb-97d1bb11abe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489ec767-971c-4f5c-85d5-b2d3285d1be5",
   "metadata": {},
   "source": [
    "**Question** : à combien de lignes peut-on s'attendre comme résultat, et pourquoi ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67ecfb6-31f9-46a5-bb8d-e7263c09c21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réponse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7833d56f-c8dd-4727-a788-48b823dd977d",
   "metadata": {},
   "source": [
    "## Création d'une UDF\n",
    "\n",
    "Pour les besoins de notre clone de Shazam, il faut être en mesure de calculer la distance euclidienne entre deux vecteurs de taille identique. Nous allons pour cela créer une UDF : _User-Defined Function_.\n",
    "\n",
    "Dans le notebook de prise en main, vous avez un exemple d’UDF qui met en rapport les éléments de 2 vecteurs passés en paramètre, comme une sorte de jointure. Elle est aussi disponible dans vos environnements sous le nom `shared.join_vectors`.\n",
    "\n",
    "Pour cette question, il est demandé de créer une autre UDF, `euclidean2`, qui retourne un flottant et non une table virtuelle, en l’occurrence le carré de la distance euclidienne entre 2 vecteurs qui lui sont passés en paramètre. Vous pourrez utiliser directement la fonction `join_vectors`, comme si son résultat était une table SQL avec 2 colonnes, une pour chaque vecteur, et une ligne par paire d’éléments. Ou vous pourrez vous en inspirer pour écrire `euclidean2` de zéro, comme vous le souhaitez.\n",
    "\n",
    "Pour rappel, si $(x_i)$ et $(y_i)$ sont deux vecteurs, le carré de cette distance est $\\sum_{i}{(x_i-y_i)^{2}}$. On ne cherche pas à appliquer une racine carrée pour avoir la distance absolue, le carré suffit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420604cf-20e2-4eab-8a4d-eb1559223981",
   "metadata": {},
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE FUNCTION binome_xxx.euclidean2 ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1148cda-16e7-4e16-9003-34897714d8f2",
   "metadata": {},
   "source": [
    "Test de la fonction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f69f02f-0270-4903-b7e5-7aa55bb4309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT binome_xxx.euclidean2([3., 1., 2.], [4., 5., 6.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa367f9-492c-4ca7-9c19-45827030c833",
   "metadata": {},
   "source": [
    "Le résultat doit être 33."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f585ac-dc93-4727-9082-9c423909e89e",
   "metadata": {},
   "source": [
    "## Calcul des distances par fenêtre\n",
    "\n",
    "Ecrire une requête qui calcule, pour chaque morceau de `vectors_with_metadata`, le carré de la distance entre tous ses vecteurs et tous ceux de la table `flat_queries` (produit cartésien). Le résultat doit avoir les colonnes suivantes :\n",
    "- `song_id_ref` (ID du morceau de référence provenant de `vectors_with_metadata`)\n",
    "- `window_id_ref` (ID de la fenêtre du vecteur du morceau de référence)\n",
    "- `query_id` (ID de la requête provenant de `flat_queries`)\n",
    "- `window_id_query` (ID de la fenêtre du vecteur issu de `flat_queries`)\n",
    "- `artist_ref`, `title_ref`, `duration_ref` : informations du morceau de référence\n",
    "- `distance2` (carré de la distance)\n",
    "\n",
    "Dans ce qui précède, `_ref` désigne donc chaque morceau de la base de référence (attention de ne pas mélanger).\n",
    "\n",
    "Il n’est pas demandé de créer une table, en revanche il faut bien copier la requête dans la cellule ci-dessous.\n",
    "\n",
    "Gardez la clause `LIMIT 100`, elle permet de n'envoyer que quelques lignes (100) au notebook ; on n'est pas intéressé par le détail pour l'instant.\n",
    "\n",
    "**Attention, c'est bien un produit cartésien que l'on veut, il n'y a pas d'égalité entre les ID de morceaux et de queries, ils n'ont rien à voir !**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f92205-faad-46c5-b3a5-174a2bc5f4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "...\n",
    "LIMIT 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b28624c-25db-47d5-b7ef-8ee0913ff404",
   "metadata": {},
   "source": [
    "Pour contrôler, voici un les premières lignes du résultat pour `song_id_ref = 43` et  `query_id = 2`, triées par `window_id_ref` et `window_id_query` :\n",
    "\n",
    "![](https://raw.githubusercontent.com/tvial/BUT-R6.01-TP3/refs/heads/main/images/check_query1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229c8116-f06d-41cb-a513-f94d204e5237",
   "metadata": {},
   "source": [
    "**Question** : comment peut-on prédire le nombre de lignes du résultat ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffe1d76-54fe-4abe-a95b-431014d2891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réponse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1fa13b-023b-4664-8b91-87c8bba61883",
   "metadata": {},
   "source": [
    "## Rapprochement des fenêtres\n",
    "\n",
    "Réutiliser la requête de la question précédente **sans la clause `LIMIT`** dans une clause `WITH` (voir notebook \"Prise en main\"), pour produire une requête qui calcule, pour chaque fenêtre de `queries` et chaque morceau de référence, la distance à la fenêtre la plus proche du morceau de référence.\n",
    "\n",
    "Structure attendue du résultat :\n",
    "- `query_id` (ID de la requête)\n",
    "- `song_id_ref` (ID du morceau de référence comparé)\n",
    "- `artist_ref`, `title_ref`, `duration_ref` : informations du morceau de référence\n",
    "- `window_id_query` (ID de la fenêtre du vecteur requêté)\n",
    "- `min_distance2` (carré de la distance la plus faible parmi les fenêtres du morceau de référence, pour un ensemble `query_id` + `window_id_query` + morceau de référence donné)\n",
    "\n",
    "Rappel : il faut retirer la clause `LIMIT` de la requête réutilisée, mais on en ajoute une sur le résultat global."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360666d9-401f-48f1-9f65-7e7dc0d1726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "...\n",
    "LIMIT 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119f5b24-84bc-4858-9952-17058ee627d9",
   "metadata": {},
   "source": [
    "## Détermination des morceaux les plus proches\n",
    "\n",
    "Une fois ceci mis au point, proposer les morceaux les plus probables pour les 3 requêtes de `flat_queries`.\n",
    "\n",
    "Pour ce faire, on peut :\n",
    "- encapsuler la requête précédente dans une nouvelle clause `WITH`\n",
    "- ... et l’utiliser dans une agrégation en calculant, pour chaque requête et chaque morceau de référence, la somme des `min_distance2`. Un tri sur le couple (somme des `min_distance2`, `query_id`) devrait vous remonter les morceaux candidats en premier.\n",
    "\n",
    "Ainsi, la \"distance\" entre 2 morceaux est la somme des distances minimales entre les fenêtres des morceaux. Principe illustré ci-dessus, pour un seul couple (`query_id`, `song_id_ref`) :\n",
    "\n",
    "![](https://raw.githubusercontent.com/tvial/BUT-R6.01-TP3/refs/heads/main/images/min_dist.png)\n",
    "\n",
    "**Vérifiez que votre requête ne contient plus aucune clause `LIMIT`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79af01b8-4a5b-44b9-af23-f7a8d6372ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858a97e9-bb9d-4a75-9c43-6502a0103f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réponse :\n",
    "# - morceau de la requête n°1 : ...\n",
    "# - morceau de la requête n°2 : ...\n",
    "# - morceau de la requête n°3 : ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401e745f-7d76-4f74-af3a-4e6da16568a5",
   "metadata": {},
   "source": [
    "# Partie 3 - Machine learning\n",
    "\n",
    "Nous continuons l’exploration des données avec la création d’un modèle de machine learning, dans BigQuery. Ce sera un modèle de clustering, opérant sur les vecteurs.\n",
    "\n",
    "On aurait aimé réutiliser notre fonction de distance `euclidean2`, mais BigQuery ML n’offre malheureusement pas la possibilité de personnaliser celle-ci. On va donc utiliser la distance euclidienne fournie.\n",
    "\n",
    "## Entraînement du modèle\n",
    "\n",
    "Le K-means de BigQuery suppose que les vecteurs sont sous forme tabulaire, et pas de tableaux imbriqués comme on en a manipulé jusqu’à présent. il faut transformer les données avant d’entraîner le modèle (on peut voir ça comme une étape de feature engineering).\n",
    "\n",
    "Nous devons donc “pivoter” les vecteurs pour en faire des colonnes. Mais il faut d’abord les “pivoter” en ligne ! On fournit la requête de pivotage dans le notebook de prise en main, vous pouvez l’exécuter pour voir son résultat.\n",
    "\n",
    "Maintenant que l’on sait pivoter les données, entraîner un modèle de type K-means, en utilisant le squelette proposé par le notebook de prise en main, sur tout le jeu de données pivoté. **La transformation doit spécifier que seules les colonnes V0 à V15 sont utilisées**.\n",
    "\n",
    "Les options du modèle doivent être :\n",
    "- `MODEL_TYPE = 'KMEANS'`\n",
    "- `NUM_CLUSTERS = 5`\n",
    "- `KMEANS_INIT_METHOD = 'KMEANS++'`\n",
    "- `DISTANCE_TYPE = 'euclidean'`\n",
    "- `STANDARDIZE_FEATURES = FALSE`\n",
    "\n",
    "Vous pouvez aller dans l'interface de BigQuery voir le détail du modèle et accéder à des statistiques sur l’entraînement, les centroïdes des clusters, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e18aa4-80e8-43ff-ba6b-1e4237104178",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951bfe87-e33e-4650-a30e-a11d33ab58e7",
   "metadata": {},
   "source": [
    "## Inférence du modèle\n",
    "\n",
    "Appliquer ensuite la fonction d’inférence sur une requête pivot similaire appliquée à `flat_queries`, et observer le résultat.\n",
    "\n",
    "Noter que le résultat ne peut pas servir à identifier facilement un morceau, car on obtient la distance aux centroïdes du modèle, qu'on ne sait pas vraiment interpréter..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755d4cc0-cc17-40a3-88d8-3ea142f1edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d53d4e-dffb-4c67-ad04-fcb3b980d1d5",
   "metadata": {},
   "source": [
    "## Exploitation du clustering sur la base de référence\n",
    "\n",
    "### Récupération\n",
    "Appliquer l'inférence non plus sur `flat_queries`, mais sur `vectors_with_metadata` elle-même (la table qui a servi à l'entraînement). Récupérer le résultat dans un dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfda7a2-7d58-4f6a-aacf-6a75c087a621",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery clustering_vmd\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cecacc-e800-46a2-98ad-dc4725f61518",
   "metadata": {},
   "source": [
    "Observer la structure du dataframe. Deux informations vont nous intéresser :\n",
    "- `song_id`, `window_id`, `artist`, etc. : informations de la fenêtre provenant d'un morceau classé\n",
    "- `CENTROID_ID` : n° du cluster auquel appartient la fenêtre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0d818a-823d-4536-9454-561ee4fecb14",
   "metadata": {},
   "source": [
    "Dans la suite, on ne fait plus appel à BigQuery mais on manipule le dataframe mémorisé à l'étape précédente, avec Pandas.\n",
    "\n",
    "Construire un nouveau dataframe avec une ligne par morceau et les colonnes suivantes :\n",
    "- `song_id` : ID du morceau\n",
    "- `artist` : nom de l'artiste\n",
    "- `centroid_id` : n° du cluster le plus fréquent pour ce morceau (associé au plus grand nombre de fenêtres)\n",
    "\n",
    "Indications : faire un regroupement du dataframe par morceau et artiste, et appliquer au regroupement une fonction qui détermine le \"mode\" de la série `CENTROID_ID` (doc Pandas ici : https://pandas.pydata.org/docs/reference/api/pandas.Series.mode.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94c323a-03a3-47ee-8e40-1eb327cedf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bce0e5-df99-4e7b-8234-0f6cf97fce7d",
   "metadata": {},
   "source": [
    "Utiliser ensuite ce dataframe pour répondre aux questions suivantes (**merci de donner le code Python en plus des réponses brutes**).\n",
    "\n",
    "**Question** : Quelles sont les nombres de morceaux par cluster ? Comment interpréter le fait que certains clusters ne soient pas du tout représentés ?\n",
    "\n",
    "**Question** : Quels sont les artistes du cluster n°1, avec combien de morceaux chacun ?\n",
    "\n",
    "**Question** : De la même manière qu'on a déterminé le cluster le plus représenté pour chaque morceau, classer les artistes par cluster le plus représenté pour leurs morceaux (en utilisant le dernier dataframe construit donc).\n",
    "\n",
    "**Question** : Le clustering des artistes n'est pas très convaincant (si vous les connaissez aussi, vous constaterez que les clusters mélangent un peu tout et n'importe quoi). En reconsidérant tout le cas d'usage, proposer des raisons possibles. **Vous pouvez répondre à cette question même si vous n'avez pas fait les précédentes !**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17579d68-5a92-416d-94db-bdbaf349d79b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
